# Load data and preprocessing

import numpy as np
from scipy.linalg import sqrtm
from scipy.stats import skewnorm
from scipy.stats import multivariate_t
from scipy.stats import multivariate_normal



# sliding windows
def data_process(Xt, p = 10, r = 0.2):
    print(Xt.shape)
    X = np.stack([Xt[i: i+p] for i in range(Xt.shape[0]-p)], axis=0)
    y = Xt[p:]
    N = X.shape[0]
    X_train = X[:int(N*(1-r))]
    y_train = y[:int(N*(1-r))]
    X_val = X[int(N*(1-r)):]
    y_val = y[int(N*(1-r)):]
    return X_train, y_train, X_val, y_val


# VAR(1)
def load_data(filename = None, n = 1000):
    if filename is not None:
        Xt = np.load(filename)
    else:
        k = 2
        A = np.array([[0.2, -0.6], [0.3, 1.1]])

        D = -A.T
        nn = 500 
        N = n + nn
        cov = np.array([[1, 0.3], [0.3, 1]])
        err = np.random.multivariate_normal(mean=np.zeros(k), cov=cov, size=N)

        XXt = np.zeros((k, N))
        for i in range(10, N):
            XXt[:, i] = A @ XXt[:, i-1] + err[i, :]

        Xt = XXt[:, nn:N]

        return Xt.T


# VAR(p) - Gaussian noise
def load_data_ptimes(p = 1, filename = None, n = 1000):
    k = 2
    A = np.zeros((p, k, k))
    if filename is None:
        for i in range(p):
            # Randomly generate a matrix whose determinant with an absolute value is 1
            A[i] = np.random.randn(k, k)
            A[i] /= np.sqrt(abs(np.linalg.det(A[i])))*p
    else :
        A = np.load(filename)
        print('A: ', A.shape)

    D = -A.transpose((0, 2, 1))
    nn = 500
    N = nn + n
    cov = np.array([[1, 0.3], [0.3, 1]])
    err = np.random.multivariate_normal(mean=np.zeros(k), cov=cov, size=N)

    XXt = np.zeros((k, N))
    for i in range(p+2, N):
        for j in range(p):
            XXt[:, i] += A[j] @ XXt[:, i-j-1]
        XXt[:, i] += err[i, :]

    Xt = XXt[:, nn:N]
    Xt = Xt.T
    if abs(Xt[-1, 0])>10 or abs(Xt[-1, 1])>10 or np.isnan(Xt[-1, 0]) or np.isnan(Xt[-1, 1]):
        Xt = load_data_ptimes(p = p)
        return Xt
    for i in range(p):
        print(f'A{i}:{A[i]}\n')
    np.save('A.npy', A)

    return Xt



# VAR(p) - skew normal noise
def load_data_p_sn(p = 1, filename = None, n = 1000):
    k = 2
    A = np.zeros((p, k, k))
    if filename is None:
        for i in range(p):
            A[i] = np.random.randn(k, k)
            A[i] /= np.sqrt(abs(np.linalg.det(A[i])))*p
    else :
        A = np.load(filename)
        print('A: ', A.shape)

    D = -A.transpose((0, 2, 1))
    nn = 500
    N = nn + n

    # Generate Skew normal Noise as independent Components
    skewness1 = 5
    skewness2 = -2

    err_skew1 = skewnorm.rvs(skewness1, size=N)
    err_skew2 = skewnorm.rvs(skewness2, size=N)
    err = np.column_stack((err_skew1, err_skew2))

    # Apply correlation
    cov = np.array([[1, 0.3], [0.3, 1]])
    L = np.linalg.cholesky(cov)  # Cholesky decomposition
    err = err @ L.T

    XXt = np.zeros((k, N))
    for i in range(p+2, N):
        for j in range(p):
            XXt[:, i] += A[j] @ XXt[:, i-j-1]
        XXt[:, i] += err[i, :]

    Xt = XXt[:, nn:N]
    Xt = Xt.T
    if abs(Xt[-1, 0])>10 or abs(Xt[-1, 1])>10 or np.isnan(Xt[-1, 0]) or np.isnan(Xt[-1, 1]):
        Xt = load_data_ptimes(p = p)
        return Xt
    for i in range(p):
        print(f'A{i}:{A[i]}\n')
    np.save('A.npy', A)

    return Xt



# VAR(p) - t noise
def load_data_p_t(p = 1, filename = None, n = 1000, df = 5):
    k = 2
    A = np.zeros((p, k, k))
    if filename is None:
        for i in range(p):
            A[i] = np.random.randn(k, k)
            A[i] /= np.sqrt(abs(np.linalg.det(A[i])))*p
    else :
        A = np.load(filename)
        print('A: ', A.shape)

    D = -A.transpose((0, 2, 1))
    nn = 500
    N = nn + n

    # Generate t distributed noise
    cov = np.array([[1, 0.3], [0.3, 1]])
    err = multivariate_t.rvs(loc=np.zeros(k), shape=cov, df=df, size=N)

    XXt = np.zeros((k, N))
    for i in range(p+2, N):
        for j in range(p):
            XXt[:, i] += A[j] @ XXt[:, i-j-1]
        XXt[:, i] += err[i, :]

    Xt = XXt[:, nn:N]
    Xt = Xt.T
    if abs(Xt[-1, 0])>10 or abs(Xt[-1, 1])>10 or np.isnan(Xt[-1, 0]) or np.isnan(Xt[-1, 1]):
        Xt = load_data_ptimes(p = p)
        return Xt
    for i in range(p):
        print(f'A{i}:{A[i]}\n')
    np.save('A.npy', A)

    return Xt



# VAR(p) - GMM noise
mu1 = np.array([-2, -2])
mu2 = np.array([2, 2])
cov = np.eye(2)
pi = 0.5

def load_gaus_mix_2p(p = 1, filename = None, n = 1000, pi = 0.5, seed=42):
    if seed is not None:
      np.random.seed(seed)

    k = 2
    A = np.zeros((p, k, k))
    if filename is None:
        for i in range(p):
            A[i] = np.random.randn(k, k)
            A[i] /= np.sqrt(abs(np.linalg.det(A[i])))*p
    else :
        A = np.load(filename)
        print('A: ', A.shape)

    D = -A.transpose((0, 2, 1))
    nn = 500
    N = nn + n

    # Generate t distributed noise
    err = np.zeros((k, N))
    for h in range(1, N):
      if np.random.rand() < pi:
        err[:, h] = np.random.multivariate_normal(mu1, cov)
      else:
        err[:, h] = np.random.multivariate_normal(mu2, cov)

    XXt = np.zeros((k, N))
    for i in range(p+2, N):
        for j in range(p):
            XXt[:, i] += A[j] @ XXt[:, i-j-1]
        XXt[:, i] += err[:, i]

    Xt = XXt[:, nn:N]
    Xt = Xt.T
    if abs(Xt[-1, 0])>10 or abs(Xt[-1, 1])>10 or np.isnan(Xt[-1, 0]) or np.isnan(Xt[-1, 1]):
        Xt = load_gaus_mix(p = p, seed=seed) # random seed
        return Xt

    return Xt



# VARMA(1,1)
Phi = np.array([[0.4, 0.1],
                [-0.2, 0.3]])
Theta = np.array([[0.5, 0.2],
                  [0.1, 0.4]])
Sigma = np.array([[1.0, -0.5],
                  [-0.5, 1.0]])


def load_arma(p = 1, n = 1000):
    k = 2
    nn = 500
    N = nn + n

    mu = np.array([0.0, 0.0])
    Phi = np.array([[0.4, 0.1],
                [-0.2, 0.3]])
    Theta = np.array([[0.5, 0.2],
                  [0.1, 0.4]])
    Sigma = np.array([[1.0, -0.5],
                  [-0.5, 1.0]])

    XXt = np.zeros((N, k)) # returns
    eps = np.zeros((N, k))  # noise

    eps[0] = np.random.multivariate_normal([0, 0], Sigma)
    XXt[0] = mu + eps[0]

    for t in range(1, N):
      eps[t] = np.random.multivariate_normal([0, 0], Sigma)
      XXt[t] = mu + Phi @ XXt[t - 1] + Theta @ eps[t - 1] + eps[t]

    Xt = XXt[nn:N, :]
    eps = eps[nn:N, :]

    if abs(Xt[-1, 0])>10 or abs(Xt[-1, 1])>10 or np.isnan(Xt[-1, 0]) or np.isnan(Xt[-1, 1]):
        Xt = load_arma(p = p)
        return Xt

    return {
         "Xt": Xt,
         "eps": eps
    }



# GARCH-BEKK(1,1,1)
C = np.array([[0.1, 0.0],
              [0.05, 0.1]])

A = np.array([[0.2, 0.0],
              [0.1, 0.3]])

B = np.array([[0.7, 0.0],
              [0.2, 0.6]])

Phi = np.array([[0.5, 0.2],
                [0.1, 0.4]])

def load_vol_VAR(p = 1, n = 1000):
    k = 2
    nn = 500
    N = nn + n

    XXt = np.zeros((N, k)) # returns
    a = np.zeros((N, k))  # noise
    Sigma = np.zeros((N, k, k)) # conditional covariance

    Sigma[0] = np.eye(k) * 0.1
    a[0] = np.random.multivariate_normal(np.zeros(k), Sigma[0])
    XXt[0] = a[0]  # with initialized 0 mean

    for t in range(1, N):
      mu_t = Phi @ XXt[t-1]

      outer_a = np.outer(a[t-1], a[t-1])
      Sigma[t] = (C @ C.T +
             A @ outer_a @ A.T +
             B @ Sigma[t-1] @ B.T)

      eps = np.random.multivariate_normal(np.zeros(k), np.eye(k))
      a[t] = np.linalg.cholesky(Sigma[t]) @ eps
      XXt[t] = mu_t + a[t]

    Xt = XXt[nn:N, :]
    a = a[nn:N, :]
    Sigma = Sigma[nn:N, :, :]

    if abs(Xt[-1, 0])>10 or abs(Xt[-1, 1])>10 or np.isnan(Xt[-1, 0]) or np.isnan(Xt[-1, 1]):
        Xt = load_vol(p = p)
        return Xt

    return {
         "Xt": Xt,
         "a": a,
         "Sigma": Sigma
    }



# Nonlinear dynamics
mu1 = np.array([-5, -1])
mu2 = np.array([2, 5])
mu3 = np.array([4, -3])
cov = np.eye(2)
# mixture weights
pi1 = 0.3
pi2 = 0.4


def load_data_nonlinear(n=1000, seed=0):
    np.random.seed(seed)
    k = 2
    nn = 500 
    N = n + nn

    # covariance
    #cov = np.array([[1, 0.3], [0.3, 1]])

    # GMM noise
    err = np.zeros((k, N))
    for h in range(1, N):
      u = np.random.rand()
      if u < pi1:
        err[:, h] = np.random.multivariate_normal(mu1, cov)
      elif u < pi1 + pi2:
        err[:, h] = np.random.multivariate_normal(mu2, cov)
      else:
        err[:, h] = np.random.multivariate_normal(mu3, cov)

    XXt = np.zeros((k, N))

    # nonlinear process 
    for i in range(10, N):
      X1, X2 = XXt[:, i-1]
      normX = np.sqrt(X1**2 + X2**2)

      f1 = 0.5 * np.sin(X1 + X2) + 0.25 * np.tanh(normX)
      f2 = (1/3) * np.cos(X1 - X2) + 0.2 * X1 / (1 + normX)

      noise_scale = 0.4 * (np.sin(normX / 5) / (2 + normX**2) + 0.5)

      XXt[:, i] = np.array([f1, f2]) + noise_scale * err[:, i]

    Xt = XXt[:, nn:N]
    err = err[:, nn:N]

    return {
        "Xt": Xt.T,
        "err": err.T}


# 6D

# VAR(1)
def load_data(filename = None, n = 1000):
    if filename is not None:
        Xt = np.load(filename)
    else:
        k = 6
        A = np.array([
            [0.2, -0.6, 0.1, 0.05, -0.1, 0.02],
            [0.3, 1.1, -0.2, 0.1, -0.05, 0.01],
            [0.1, 0.2, 0.8, -0.1, 0.05, -0.02],
            [0.05, -0.1, 0.1, 0.7, 0.1, -0.05],
            [-0.1, 0.05, 0.05, 0.1, 0.9, 0.03],
            [0.02, 0.01, -0.02, -0.05, 0.03, 0.85]
        ])

        D = -A.T
        nn = 500  
        N = n + nn

        cov = np.array([
                [1.0, 0.3, 0.2, 0.1, 0.05, 0.02],
                [0.3, 1.0, 0.1, 0.15, 0.08, 0.03],
                [0.2, 0.1, 1.0, 0.12, 0.06, 0.04],
                [0.1, 0.15, 0.12, 1.0, 0.2, 0.1],
                [0.05, 0.08, 0.06, 0.2, 1.0, 0.15],
                [0.02, 0.03, 0.04, 0.1, 0.15, 1.0]
        ])
        err = np.random.multivariate_normal(mean=np.zeros(k), cov=cov, size=N)

        XXt = np.zeros((k, N))
        for i in range(10, N):
            #XXt[:, i] = A @ (0.6*XXt[:, i-1] + 0.4 * XXt[:, i-5]) + err[i, :]
            XXt[:, i] = A @ XXt[:, i-1] + err[i, :]

        Xt = XXt[:, nn:N]

        return Xt.T











